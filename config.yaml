# 0: background, 1: ich, 2: ivh, 3: edh,sdh, 4: sah
model:
  SwinV2_Base_256:
    weight_name: swinv2_base_window12to16_192to256_22kft1k
    num_classes: 7

dataset:
  img_shape: [256, 256]
  dataset_path: './dataset'
  train_valid_split_ratio: 0.7
  random_sate: 777

trainer:
  experiment_name: Food_Classification
  run_name: Base_01
  cuda_device: '0'
  num_workers: 8  # Dataloader worker
  apply_aug: True  # Train시 Augmentation 적용여부

  # Sampler params
  train_custom_weights: {}
  
  # Lr, Loss_value, Batch_size
  lr: 1.0e-4
  train_batch_size: 16
  valid_batch_size: 32

  # Epoch, chkpoint params
  start_epoch: 1
  target_epoch: 350
  cut_iter: -1  # epoch당 iteration limit, -1 : 모든 iteration 학습
  min_chkpoint_epoch: 20  # 최소 체크포인트 저장 에포크
  chkpoint_metric: 'valid_loss'  # ['valid_acc', 'valid_loss']

optimizer:
  SGD:
    momentum: 0.9
    weight_decay: 0.0001
  AdamW:
    weight_decay: 0.01  # default 0.01

scheduler:
  NoneScheduler: {}  # Fixed LR
  CustomCosineAnnealingWarmupRestarts:
    cycle_mult: 1
    min_lr: 1.0e-6  # 한 사이클당 최저 lr 값
    warmup_steps: 50
    gamma_last_lr: 3.5e-5
    # first_cycle_steps: 495  # len(train_loader)로 자동적용
    # gamma: 0.9958095161851701  # gamma_min_lr을 설정하면 마지막 epoch에 해당값이 되는 gamma값 자동계산
  ExpTargetIterScheduler:
    gamma: 0.9
    min_lr: 1.0e-7
    target_iteration: 15000  # lr이 0되는 지점